## Запуск
docker-compose up

- Загрузка файла: curl --form file='@filename' http://127.0.0.1:8081/upload --cookie "s3_token=not_very_secret_auth"
- Получить файл: http://127.0.0.1:8081/get?file_id=file_id

## Упрощения
1. Вместо БД для тестирования используется mock-file c данными о загруженных файлах.

2. Информация о серверах хранения при старте хранится в конфиг файле, при таком условии можно или запустить http-ручку на другом порту
для добавления нового сервера, или использовать полудинамические конфиги, где файл читается с диска заново после его обновления.
В реальной системе я бы использовал sql-БД или Редис для хранения информации о серверах, и брокер сообщений для обновлений.

3. Проблемы с отказом одного из серверов хранения. Нет репликации или кодов избыточности для восстановления данных при отказе одного или нескольких дисков.
Например, для кодов избыточности можно было воспользоваться такой библиотекой: https://github.com/klauspost/reedsolomon?tab=readme-ov-file

4. Если загрузка файла оборвалась, можно было бы не грузить файл заново, а восстановить его по уже загруженным частям, сверяя по md5 сумме.
Сейчас можно загрузить только новый файл.

5. Нет bucket'ов для конкретного пользователя, используется уникальный идентификатор для файла, который нужно знать, чтобы получить ресурс

## Описание
Сервер А(uploader) запускается на 8081 порту и имеет два http-хэндлера /upload и /get. Для общения с сервером Б(object-storage) используется grpc.

При загрузке файла object-storage создает директорию, где имя это ID-шник файла, внутри хранятся пронумерованные объекты - части файла(На случай если серверов хранения у нас мало и было загружено два объекта в один сервер).

Uploader достает и записывает в БД(вместо БД mock заглушка) мета-информацию о файле, включая сервера, на которых хранятся части файла.
Для балансировки между grpc-серверами хранения используется простой балансер с round robin алгоритмом.
Часть логики изолирована в domain'е без лишних зависимостей для упрощения написания unit-тестов.
